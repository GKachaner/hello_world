{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GcsY9Yhr2Wki"
      },
      "source": [
        "# MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4NfjZf82cdX",
        "outputId": "a65a6cec-96e7-41cc-e2e8-8ec0403d51a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "modelMNIST = tf.keras.models.Sequential()\n",
        "modelMNIST.add(tf.keras.layers.Flatten())\n",
        "modelMNIST.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "modelMNIST.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "modelMNIST.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "modelMNIST.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQlVd6gH2hi6",
        "outputId": "0eeb6230-7259-40c5-e64a-fa2cc35e2a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_trainMNIST, y_trainMNIST), (x_testMNIST, y_testMNIST) = mnist.load_data()\n",
        "x_trainMNIST = tf.keras.utils.normalize(x_trainMNIST, axis=1)\n",
        "x_testMNIST = tf.keras.utils.normalize(x_testMNIST, axis=1)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_bul3BF2oqs",
        "outputId": "859f1ba6-77d7-404e-82c4-f999085a4e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_testMNIST.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DD59YfZU2pqK",
        "outputId": "6eb95027-f3b5-48bd-cc1d-9ddd1617a832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "modelMNIST.fit(x_trainMNIST,y_trainMNIST, epochs=3)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2655 - acc: 0.9217\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1081 - acc: 0.9668\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0736 - acc: 0.9764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e62472e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JygQ6xZM2rKW",
        "outputId": "60ccfe5b-6040-450a-a7a1-a462e4009e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_lossMNIST, val_accMNIST = modelMNIST.evaluate(x_testMNIST,y_testMNIST)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 32us/sample - loss: 0.1080 - acc: 0.9673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ik_C-FHB2vNB",
        "outputId": "a51df1b1-814b-48e1-af13-fac1d6f0cb71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"loss:\",val_lossMNIST)\n",
        "predictionsMNIST = modelMNIST.predict(x_testMNIST)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.10798338177073746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VjBXbCRY20BB",
        "outputId": "d54a6c79-3796-4e3e-dd81-31c0ad95196d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "import random\n",
        "indexMNIST = random.randint(0,999)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_testMNIST[indexMNIST])\n",
        "plt.show()\n",
        "print(np.argmax(predictionsMNIST[indexMNIST]))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZmfMZ_Uaq-r0"
      },
      "source": [
        "# MR BRAIN WITHOUT DATA AUGMENTATION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "06rWGhVOq-r4",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = np.load('mrbraintrainx.npy')\n",
        "y_train = np.load('mrbraintrainy.npy')\n",
        "x_test = np.load('mrbraintestx.npy')\n",
        "y_test = np.load('mrbraintesty.npy')\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4efa5006-a59a-49b2-b4eb-8c9e6213bc7d",
        "id": "XrxvNtevq-r7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}-no-aug.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=150, batch_size=10, callbacks=[checkpoint], verbose=0)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.45000, saving model to saved-model-01-0.45-no-aug.hdf5\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.45000\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.45000 to 0.50000, saving model to saved-model-03-0.50-no-aug.hdf5\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.50000\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.50000 to 0.55000, saving model to saved-model-21-0.55-no-aug.hdf5\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.55000\n",
            "\n",
            "Epoch 00028: val_acc improved from 0.55000 to 0.65000, saving model to saved-model-28-0.65-no-aug.hdf5\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.65000\n",
            "\n",
            "Epoch 00062: val_acc improved from 0.65000 to 0.70000, saving model to saved-model-62-0.70-no-aug.hdf5\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.70000\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.70000\n",
            "\n",
            "Epoch 00065: val_acc improved from 0.70000 to 0.75000, saving model to saved-model-65-0.75-no-aug.hdf5\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.75000\n",
            "\n",
            "Epoch 00094: val_acc improved from 0.75000 to 0.80000, saving model to saved-model-94-0.80-no-aug.hdf5\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00109: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00118: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00141: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.80000\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.80000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e5a29efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oFudOMWyq-r-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd78510e-308a-421a-e854-77fc9eecd495"
      },
      "source": [
        "\n",
        "val_loss, val_acc = model.evaluate(x_test,y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 0s 76us/sample - loss: 0.7405 - acc: 0.4500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M3SAh588q-sA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a61bec0-7e16-497c-c9c8-4177a9aa2109"
      },
      "source": [
        "print(\"loss:\",val_loss)\n",
        "predictions = model.predict(x_test)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.7405394911766052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SYmaaf2nq-sD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "11e26bd9-1e5a-4d65-f2e5-730c597560e1"
      },
      "source": [
        "import random\n",
        "index = random.randint(0,19)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test[index], cmap='gray')\n",
        "plt.show()\n",
        "if(np.argmax(predictions[index]) == 1):\n",
        "  print('Brain !')\n",
        "else:\n",
        "  print('Not brain !')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGHZJREFUeJztnV9sXdWVxr+F8z924sT55wQUl4R2\nEioakIlAoIopKkpppRRphOCh4gE11ahIg9R5QIw0ZaR5oKMBhMSIkZkg6IjhzxQQCKGZMrRSBA8U\nA8GBZgbSlBIHx46bP3ZCgNhZ83BPJCec9d3rbfvchP39pCjXe919zrr73M/Xd39n7W3uDiFEflzQ\n7ASEEM1B4hciUyR+ITJF4hciUyR+ITJF4hciUyR+ITJF4hciUyR+ITJl1lQ6m9kWAA8CaAHwb+5+\nL3t+e3u7r1q1qjR28uTJsN/w8HBpO7s7sb29PYy1tbWFsaGhoUnnYWZhn9mzZ4exRYsWhbG5c+eG\nMXa+iJaWljA2Z86cMMbG+Isvvph0HoxTp04lxVIYHx9POlfK2AN8HKNjzpoVy/OCC8o/tw8fPoxj\nx441lGSy+M2sBcC/APgugH4Ab5rZi+7++6jPqlWr0NPTUxo7cOBAeK7HHnustP2zzz4L+2zdujWM\nXX/99WHsoYceCmPbt28vbWdviNWrV4exG264IYytX78+jLHzRbElS5aEfS688MIw9vnnn4exgYGB\nMBYJiOV+4sSJMDY6OhrGUhgZGUnKgwmSMTY2FsaiD4jly5eHfRYsWFDaft999zWc01T+7N8MYI+7\n73X3LwA8BSBWnBDinGIq4l8DYN+En/uLNiHEecCMT/iZ2TYz6zWz3iNHjsz06YQQDTIV8e8HcNGE\nny8s2s7A3Xvcvdvdu9kknBCiWqYi/jcBXGJmXzOzOQBuAfDi9KQlhJhpkmf73X3MzO4A8N+oWX2P\nuvv7rM/Q0BAefvjh0hj7qyCyNTo6OsI+zK759NNPwxiz+iIWLlyYFJs3b14YY1bU8ePHw1g0m87G\nitmKbJa6tbU1jEU5suOx18xIsd+YBctm9NlYMTuPOVORzc1ch4jJWKJT8vnd/WUAL0/lGEKI5qA7\n/ITIFIlfiEyR+IXIFIlfiEyR+IXIlCnN9k+W0dFR/OY3vymNsQKYqIhh3bp1YZ81a+I7jVmRCKsu\njKy5xYsXh31YBSGzAZkVxSyxKP+jR4+GfVjxDoPlGFURsnOxGLO9mMUW5cFsVmb1pVZAMgsuumbM\nFp0O9MkvRKZI/EJkisQvRKZI/EJkisQvRKZUOts/NjYWFs5ExTsAsGHDhtL2iy++OOwTOQRAbZ2z\nFFasWFHazmaHWSxltrxeLJpVZg4HK3Ri50pZl47NlrNrxlwY5hJE7yv2fmMx5rSkruXInIeI6VjT\nUJ/8QmSKxC9Epkj8QmSKxC9Epkj8QmSKxC9EplRq9c2aNSvcOYbZK1GRDiuoYRZVf39/GEvZWYVZ\nXux4zGJLXSuOjWME23aL5cHspsgSY9eFbV/GLFNmY0YFQWxNvZQxBLidxyzO6HzM3pTVJ4RIRuIX\nIlMkfiEyReIXIlMkfiEyReIXIlOmZPWZ2UcARgGMAxhz9272/Llz54br7jG7af369ZPOjVk5w8PD\nkz4eg9l5zK5h69KlWmyRpcRsNHY8dl1YNV00JqlVjqlbm0V5HDt2LOzDrNTU/FNeG7OCp2N9v+nw\n+f/S3adXTUKIGUd/9guRKVMVvwP4tZm9ZWbbpiMhIUQ1TPXP/mvdfb+ZrQDwipn9r7vvmPiE4pfC\nNoDf4iiEqJYpffK7+/7i/yEAzwPYXPKcHnfvdvduNukhhKiWZPGb2UIzazv9GMANAN6brsSEEDPL\nVP7sXwng+WLRwlkA/sPd/4t1YFYfsy7Wrl1b2s4sGWZDMbumvb09jKXYK+xc8+fPT+rH8oi+WrHF\nMdk4Mst0ZGQkjEX2G9uijNmKzDJlVXiRZZpqz7KvruyaMTs1WviT2b2RPTiZisRk8bv7XgDfSu0v\nhGgusvqEyBSJX4hMkfiFyBSJX4hMkfiFyJRKF/A8depUWKl02WWXhf1aW1tL21llFrNrOjo6wli0\nHx8QWznMKmMWW1tbWxhjNg973ZGlxGwoZl8xy5RVnUX2FavOY3vdMVLuHGW2YkrVJMBtTPYeiXJh\n1YrsejaKPvmFyBSJX4hMkfiFyBSJX4hMkfiFyJTKt+tatmxZaayrq2taz8UKN9isLHMJotlXNgPM\nypjZ7HbqzHeUPyvQYTPwbOabjVU0u836sEIn5n6kzHynbDUG8OvJ8mfHjK7N8ePHwz5RAQ87z5eO\n0fAzhRBfKSR+ITJF4hciUyR+ITJF4hciUyR+ITLlnLH6Fi9eHPabjH0x8VwRrFhlYGAgjEUFRi0t\nLWEfZlGNjo6GMWYpMasysjjZuRipllg0xmysUscxZe08ZgWzIpzUdSPZWEWFPSlWKrteZ6NPfiEy\nReIXIlMkfiEyReIXIlMkfiEyReIXIlPqWn1m9iiAHwAYcvdvFm1LATwNoAvARwBudvfD9Y41b948\nbNiwoTTGrC1moUQw2+jw4ThVti5dZPWtWrUq7LN69eowduDAgTC2cuXKMMasvih/9rpSxhfglYLR\nMZkVxSw7VnnIiCw99v5gsNd84sSJMMZsuwi29VaK/f2l4zfwnMcAbDmr7S4Ar7r7JQBeLX4WQpxH\n1BW/u+8AcOis5q0AHi8ePw7gh9OclxBihkn9zr/S3U/fCncAtR17hRDnEVOe8PPafYbhPY9mts3M\nes2sN/UWUyHE9JMq/kEz6wSA4v+h6Inu3uPu3e7ezTapEEJUS6r4XwRwW/H4NgAvTE86QoiqaMTq\nexLAdQCWmVk/gJ8DuBfAM2Z2O4A/Abi5kZPNmTMntL6Gh4fDfpFtxKwV9hXj448/DmOM9vb20vZL\nL7007MMsKrZlFKtiY7ZoZA8xO49t/8VgeUQxtjBp6hZa7JiRfcisPla5l2r1MWsusm6Z9Rnlz+zB\nLx2/3hPc/dYgdH3DZxFCnHPoDj8hMkXiFyJTJH4hMkXiFyJTJH4hMqXSBTzdPayyYjbP0FD5PURR\nO8Dtq08++SSMdXR0hLHIbmJW0/Lly8PYyMhIGGOw1xYd8+jRo2EfVvHH9iFksQULFoSxFFKr2FIs\nMXYuZgOmWI7smCyPlP0Jz0af/EJkisQvRKZI/EJkisQvRKZI/EJkisQvRKZUavWdPHky3AsvpeqM\nVQIeP348KbZ06dIwFuXILJ5FixaFMWaHMRuQjVVUWcb2pmO2F6vcY5WHkQ3IcmeW45EjR8IYs8RS\n7NnU8WAxRmRzs2sWxbRXnxCiLhK/EJki8QuRKRK/EJki8QuRKZXP9g8ODpbG1qxZE/aLZuDZDDAr\nZGHbXc2fPz+MpRSJsBlgto7cvn37whhzEKJjstfMZsvZjD4rLomOyQq4WIxdT7auXnQ9U9ZBBPhs\nOhtHNnMf9WNbfEXFQKzw6Gz0yS9Epkj8QmSKxC9Epkj8QmSKxC9Epkj8QmRKI9t1PQrgBwCG3P2b\nRds9AH4M4GDxtLvd/eVGThhZEWztvMiW6e/vD/swG3Dt2rVhbMWKFWEsKgZhdhizeJhVxvqxopTI\n0mMFNazQiVlbzFZKWXMv1RZl4xHFUs/FtuRKsfNYLiyP6FxsLM6mkU/+xwBsKWl/wN03Ff8aEr4Q\n4tyhrvjdfQeAQxXkIoSokKl857/DzPrM7FEzWzJtGQkhKiFV/A8DWAdgE4ABAPdFTzSzbWbWa2a9\n7LulEKJaksTv7oPuPu7upwA8AmAzeW6Pu3e7eze7v1wIUS1J4jezzgk/3gTgvelJRwhRFY1YfU8C\nuA7AMjPrB/BzANeZ2SYADuAjAD9p5GRmFtpi7K+C6OsCq+bav39/GFu9enUY27BhQxiLcmeWI6tU\nY9V5DGYRRjG2Ph77OsaqHJnFGb1uZjnOmzcvjLH3B+sXwWzKlDUSAV6FxyoFo/xZnyhH1uds6orf\n3W8tad7e8BmEEOckusNPiEyR+IXIFIlfiEyR+IXIFIlfiEypdAHPsbExHDx4sDTG7JUIVsHEqvqY\nNcdso8ja6uzsLG0HeKXX8uXLw9jixYvDGHvdkd3E8mAWFbP6WB5RFRu7zux4qflHx2THY7ZoytZg\nALcWI8s6ZTu06a7qE0J8BZH4hcgUiV+ITJH4hcgUiV+ITJH4hciUSq2+8fFxjIyMlMaidiCuOov2\n8APSF9X84IMPwtiWLWVLGQKjo6NhHxZj1XnstTG7LLKi2LmYvcmqxJitFC0+yRbOZNfl0KF4JbkU\ne3YylthEIoutXoxVoLJYxIIFCybd52z0yS9Epkj8QmSKxC9Epkj8QmSKxC9EplQ623/BBReEs5RR\nwQ8AtLa2lrazGXG2JdfHH38cxnbt2hXGrrvuutJ2NnPMin4GBwfDGDtmyuw8m+1PmW0G0rYUY1tQ\npZ6LrUEYFdSw2XI2a8/GkcEKgqKxYnlMZq2+8BhTPoIQ4rxE4hciUyR+ITJF4hciUyR+ITJF4hci\nUxrZrusiAL8EsBK17bl63P1BM1sK4GkAXaht2XWzux+mJ5s1C0uWlO/m/cknn4T9orXuWJHI1Vdf\nHcaOHTsWxg4cOBDGouKjtra2sE97e3sY6+vrC2OHD8dDuXLlyjAW2UNs2zBm9TGLKmXbMGZTsjXw\nUoneI2xtQgYbR2ZHMqKxYrYouy6N0sgn/xiAn7n7RgBXAfipmW0EcBeAV939EgCvFj8LIc4T6orf\n3Qfc/e3i8SiA3QDWANgK4PHiaY8D+OFMJSmEmH4m9Z3fzLoAXA7gDQAr3X2gCB1A7WuBEOI8oWHx\nm1krgGcB3OnuZ3z59do9lKX3UZrZNjPrNbNedhumEKJaGhK/mc1GTfhPuPtzRfOgmXUW8U4AQ2V9\n3b3H3bvdvZvtsS6EqJa64rda1cF2ALvd/f4JoRcB3FY8vg3AC9OfnhBipmikROkaAD8CsMvMdhZt\ndwO4F8AzZnY7gD8BuLnegVpaWsJtqJhNsnfv3tJ2VtX3jW98I4ylbte1b9++0vZrrrkm7MO2fmJ2\nHqsGZBZbVMXGvnIx65PZTeyaRTmyajS27RaDXbNFixaVtjMLluXBbFFmA7LXHY0xG9/I6puMXVpX\n/O7+GoCovvT6hs8khDin0B1+QmSKxC9Epkj8QmSKxC9Epkj8QmTKObOA5/DwcNgv2vLq61//etgn\nqgQEgK6urjD2zjvvhLHXXnuttD1aYBTglhKrSmRWH7OUooVQ2RZfzM5jMWZfRa8tsiIBXqmW2i+K\npdhoAF9Uk8HGKoqlWJ+T2YZMn/xCZIrEL0SmSPxCZIrEL0SmSPxCZIrEL0SmVGr1zZo1C8uWLSuN\n7dy5s7QdiCvjmBXCrBxmzc2dOzeMHTp0qLT9lVdeCfswO5LZeVE1GgCcOHEijEW2KKt8YzFmHbFY\nVNXHqs5YtSK7nqzSLrpmzPpM3Y+P2XmTseBOk7Kvoaw+IURdJH4hMkXiFyJTJH4hMkXiFyJTKp3t\nHx8fD7e8GhgYKG0H4hlstgYemy1n211t3LgxjO3atau0PZpRBoDXX389jF155ZVhjI0Hcyuioh+2\npVjqdl2MaDadzfanzIgDvOgnem3MKWKz/SxHNtvPXKQoxo5X1XZdQoivIBK/EJki8QuRKRK/EJki\n8QuRKRK/EJlS1+ozs4sA/BK1LbgdQI+7P2hm9wD4MYDTi8bd7e4vs2ONj4/jyJEjpTFWxBBZISkW\nDwBs3rw5jH3/+98PY88991xp+0svvRT2YXbkH//4xzA2f/78MMbsssjSY8U7Kdt/1YMVzkSkrMVX\nj+h9lVI0U49UGzCKpVqfjdKIzz8G4Gfu/raZtQF4y8xOl7E94O7/PHPpCSFmikb26hsAMFA8HjWz\n3QDWzHRiQoiZZVLf+c2sC8DlAN4omu4wsz4ze9TMlkxzbkKIGaRh8ZtZK4BnAdzp7iMAHgawDsAm\n1P4yuC/ot83Mes2sl20FLYSolobEb2azURP+E+7+HAC4+6C7j7v7KQCPACidRXP3Hnfvdvdudk+6\nEKJa6orfalOO2wHsdvf7J7RPXIPqJgDvTX96QoiZopHZ/msA/AjALjM7vdDe3QBuNbNNqNl/HwH4\nSb0DuXto2SxcuDDst379+tL2jo4Oeq4IVtG1atWqMLZly5bSdlaBt2PHjjAWrU0I8Mo9ZmNGVmq0\nTRqQvk1WihXFjsdizN5k1zPKkY0H20aNWXbMMmXbfKVs1xVds8lYs43M9r8GoGwEqacvhDi30R1+\nQmSKxC9Epkj8QmSKxC9Epkj8QmRK5Qt4RotxMmtr3bp1pe3RsQBuk3z44YdhbNOmTWFs9erVpe2X\nX3552Of9998PY8xuWrIkvluaVaRFFhCz5dhWWMwGZLZXZJexPNjrYteTWabRa2PWMltsM2WLsnrH\njMY4WoyVxSZj9emTX4hMkfiFyBSJX4hMkfiFyBSJX4hMkfiFyJRKrb5Tp04hWtCDLfgY2RqsUurP\nf/5zGDt69GgY2717dxiLztfZ2VnaDvB9AVkex48fD2NsMc5o4U9m57EqQWaxsUq7yMZMtdHYudhr\nY/ZbRGrlYeoCntH7m71mdrxG0Se/EJki8QuRKRK/EJki8QuRKRK/EJki8QuRKZVafS0tLWhvby+N\nsUUTDx48WNrO9gGIFrIE+CKd/f39YWzDhg2l7Wwh0Y0bN4axN998M4wxq5JVQEZ2JLONGCkVhEBs\nEaYujsn6sQq9qB87V+qCptNtEbKqz8juncwehPrkFyJTJH4hMkXiFyJTJH4hMkXiFyJT6s72m9k8\nADsAzC2e/yt3/7mZfQ3AUwA6ALwF4EfuHi86htpMZFtbWxiL2LNnT2n73r17wz6sMIbN9LKZ46iA\nh80Os/X92Ix+X19fGEuZjWavmRXvpM7Ap8yysyKcqGAJ4AU1USx1LUG2rt6JEyeS+i1atKi0nbk6\nUf7TPdv/OYDvuPu3UNuOe4uZXQXgFwAecPf1AA4DuL3hswohmk5d8XuN04b67OKfA/gOgF8V7Y8D\n+OGMZCiEmBEa+s5vZi3FDr1DAF4B8AcAR9z9dCF1P4A1M5OiEGImaEj87j7u7psAXAhgM4C/aPQE\nZrbNzHrNrJfdkSeEqJZJzfa7+xEAvwVwNYB2Mzs9Q3MhgP1Bnx5373b3bjaBIYSolrriN7PlZtZe\nPJ4P4LsAdqP2S+CviqfdBuCFmUpSCDH9NFLY0wngcTNrQe2XxTPu/pKZ/R7AU2b2jwDeAbC9kRNG\nVsTrr78e9nn33XdL2wcHB8M+zLLr6uoKY8xSitafYzYOK/qJbE+A2zxszbpoXUBmbTGrjxWXsFhU\nYMTsPGZTpRYYResTTve6fwAvNEsZY5ZHZJmy6/yl49d7grv3AfiSWe3ue1H7/i+EOA/RHX5CZIrE\nL0SmSPxCZIrEL0SmSPxCZIqxtcWm/WRmBwH8qfhxGYDhyk4eozzORHmcyfmWx1p3X97IASsV/xkn\nNut19+6mnFx5KA/loT/7hcgViV+ITGmm+HuaeO6JKI8zUR5n8pXNo2nf+YUQzUV/9guRKU0Rv5lt\nMbP/M7M9ZnZXM3Io8vjIzHaZ2U4z663wvI+a2ZCZvTehbamZvWJmHxb/L2lSHveY2f5iTHaa2Y0V\n5HGRmf3WzH5vZu+b2d8U7ZWOCcmj0jExs3lm9jsze7fI4x+K9q+Z2RuFbp42s/LSyUZx90r/AWhB\nbRmwiwHMAfAugI1V51Hk8hGAZU0477cBXAHgvQlt/wTgruLxXQB+0aQ87gHwtxWPRyeAK4rHbQA+\nALCx6jEheVQ6JgAMQGvxeDaANwBcBeAZALcU7f8K4K+ncp5mfPJvBrDH3fd6banvpwBsbUIeTcPd\ndwA4dFbzVtQWQgUqWhA1yKNy3H3A3d8uHo+itljMGlQ8JiSPSvEaM75objPEvwbAvgk/N3PxTwfw\nazN7y8y2NSmH06x094Hi8QEAK5uYyx1m1ld8LZjxrx8TMbMu1NaPeANNHJOz8gAqHpMqFs3NfcLv\nWne/AsD3APzUzL7d7ISA2m9+1H4xNYOHAaxDbY+GAQD3VXViM2sF8CyAO919ZGKsyjEpyaPyMfEp\nLJrbKM0Q/34AF034OVz8c6Zx9/3F/0MAnkdzVyYaNLNOACj+H2pGEu4+WLzxTgF4BBWNiZnNRk1w\nT7j7c0Vz5WNSlkezxqQ496QXzW2UZoj/TQCXFDOXcwDcAuDFqpMws4Vm1nb6MYAbALzHe80oL6K2\nECrQxAVRT4ut4CZUMCZWW3huO4Dd7n7/hFClYxLlUfWYVLZoblUzmGfNZt6I2kzqHwD8XZNyuBg1\np+FdAO9XmQeAJ1H78/Ekat/dbkdtz8NXAXwI4H8ALG1SHv8OYBeAPtTE11lBHtei9id9H4Cdxb8b\nqx4TkkelYwLgMtQWxe1D7RfN3094z/4OwB4A/wlg7lTOozv8hMiU3Cf8hMgWiV+ITJH4hcgUiV+I\nTJH4hcgUiV+ITJH4hcgUiV+ITPl/bBoBXMX0H8YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Not brain !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33yd5hXMNOgn",
        "colab_type": "text"
      },
      "source": [
        "# MR BRAIN WITH DATA AUGMENTATION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DPbPVak1NWoK",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(32,32,1)))\n",
        "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = np.load('mrbraintrainx.npy')\n",
        "y_train = np.load('mrbraintrainy.npy')\n",
        "x_test = np.load('mrbraintestx.npy')\n",
        "y_test = np.load('mrbraintesty.npy')\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXVG06yVN9tG",
        "colab_type": "code",
        "outputId": "125f3f08-c742-4010-aa25-aa138e26c181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}-with-aug.hdf5\"\n",
        "\n",
        "x_train_augmented = x_train[:,:,:,np.newaxis]\n",
        "x_test_augmented = x_test[:,:,:,np.newaxis]\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip = True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train_augmented,y_train, batch_size=1000),steps_per_epoch=40,epochs=50,validation_data=(x_test_augmented,y_test),callbacks=[checkpoint])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6842 - acc: 0.5604\n",
            "Epoch 00001: val_acc improved from -inf to 0.40000, saving model to saved-model-01-0.40-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 108ms/step - loss: 0.6836 - acc: 0.5616 - val_loss: 0.7130 - val_acc: 0.4000\n",
            "Epoch 2/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6290 - acc: 0.6149\n",
            "Epoch 00002: val_acc improved from 0.40000 to 0.50000, saving model to saved-model-02-0.50-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 98ms/step - loss: 0.6284 - acc: 0.6152 - val_loss: 0.7441 - val_acc: 0.5000\n",
            "Epoch 3/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5853 - acc: 0.6422\n",
            "Epoch 00003: val_acc did not improve from 0.50000\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 0.5848 - acc: 0.6428 - val_loss: 0.7273 - val_acc: 0.4500\n",
            "Epoch 4/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5508 - acc: 0.6814\n",
            "Epoch 00004: val_acc did not improve from 0.50000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.5504 - acc: 0.6821 - val_loss: 0.7024 - val_acc: 0.4500\n",
            "Epoch 5/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5289 - acc: 0.7077\n",
            "Epoch 00005: val_acc did not improve from 0.50000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.5285 - acc: 0.7083 - val_loss: 0.6895 - val_acc: 0.5000\n",
            "Epoch 6/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4941 - acc: 0.7414\n",
            "Epoch 00006: val_acc improved from 0.50000 to 0.55000, saving model to saved-model-06-0.55-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4938 - acc: 0.7416 - val_loss: 0.6502 - val_acc: 0.5500\n",
            "Epoch 7/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.7549\n",
            "Epoch 00007: val_acc did not improve from 0.55000\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 0.4765 - acc: 0.7555 - val_loss: 0.6457 - val_acc: 0.5500\n",
            "Epoch 8/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.7774\n",
            "Epoch 00008: val_acc improved from 0.55000 to 0.60000, saving model to saved-model-08-0.60-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4475 - acc: 0.7771 - val_loss: 0.6060 - val_acc: 0.6000\n",
            "Epoch 9/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.7849\n",
            "Epoch 00009: val_acc improved from 0.60000 to 0.65000, saving model to saved-model-09-0.65-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4337 - acc: 0.7840 - val_loss: 0.6019 - val_acc: 0.6500\n",
            "Epoch 10/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.7986\n",
            "Epoch 00010: val_acc improved from 0.65000 to 0.70000, saving model to saved-model-10-0.70-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4124 - acc: 0.7988 - val_loss: 0.5768 - val_acc: 0.7000\n",
            "Epoch 11/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8025\n",
            "Epoch 00011: val_acc did not improve from 0.70000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.4016 - acc: 0.8017 - val_loss: 0.5925 - val_acc: 0.6000\n",
            "Epoch 12/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3837 - acc: 0.8142\n",
            "Epoch 00012: val_acc did not improve from 0.70000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3834 - acc: 0.8148 - val_loss: 0.5859 - val_acc: 0.6500\n",
            "Epoch 13/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3681 - acc: 0.8219\n",
            "Epoch 00013: val_acc did not improve from 0.70000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3684 - acc: 0.8221 - val_loss: 0.6185 - val_acc: 0.6500\n",
            "Epoch 14/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3745 - acc: 0.8164\n",
            "Epoch 00014: val_acc improved from 0.70000 to 0.75000, saving model to saved-model-14-0.75-with-aug.hdf5\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3739 - acc: 0.8174 - val_loss: 0.5555 - val_acc: 0.7500\n",
            "Epoch 15/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3444 - acc: 0.8389\n",
            "Epoch 00015: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3442 - acc: 0.8389 - val_loss: 0.5743 - val_acc: 0.7000\n",
            "Epoch 16/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3322 - acc: 0.8440\n",
            "Epoch 00016: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3323 - acc: 0.8442 - val_loss: 0.5829 - val_acc: 0.6500\n",
            "Epoch 17/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3436 - acc: 0.8336\n",
            "Epoch 00017: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3431 - acc: 0.8340 - val_loss: 0.5571 - val_acc: 0.6500\n",
            "Epoch 18/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8557\n",
            "Epoch 00018: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3142 - acc: 0.8561 - val_loss: 0.5482 - val_acc: 0.7000\n",
            "Epoch 19/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.8628\n",
            "Epoch 00019: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3056 - acc: 0.8626 - val_loss: 0.6175 - val_acc: 0.6000\n",
            "Epoch 20/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3027 - acc: 0.8608\n",
            "Epoch 00020: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3024 - acc: 0.8612 - val_loss: 0.5412 - val_acc: 0.7000\n",
            "Epoch 21/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.8542\n",
            "Epoch 00021: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.3114 - acc: 0.8539 - val_loss: 0.5614 - val_acc: 0.7000\n",
            "Epoch 22/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2841 - acc: 0.8773\n",
            "Epoch 00022: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2840 - acc: 0.8771 - val_loss: 0.5727 - val_acc: 0.6500\n",
            "Epoch 23/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.8803\n",
            "Epoch 00023: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2741 - acc: 0.8802 - val_loss: 0.5743 - val_acc: 0.6500\n",
            "Epoch 24/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.8762\n",
            "Epoch 00024: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2759 - acc: 0.8767 - val_loss: 0.5861 - val_acc: 0.6000\n",
            "Epoch 25/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.8874\n",
            "Epoch 00025: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2617 - acc: 0.8875 - val_loss: 0.6070 - val_acc: 0.6500\n",
            "Epoch 26/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.8681\n",
            "Epoch 00026: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2842 - acc: 0.8685 - val_loss: 0.7268 - val_acc: 0.6000\n",
            "Epoch 27/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.8955\n",
            "Epoch 00027: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2504 - acc: 0.8956 - val_loss: 0.5911 - val_acc: 0.6500\n",
            "Epoch 28/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.8994\n",
            "Epoch 00028: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2412 - acc: 0.8988 - val_loss: 0.5928 - val_acc: 0.5000\n",
            "Epoch 29/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9021\n",
            "Epoch 00029: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2364 - acc: 0.9024 - val_loss: 0.6458 - val_acc: 0.6000\n",
            "Epoch 30/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9041\n",
            "Epoch 00030: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2320 - acc: 0.9039 - val_loss: 0.6899 - val_acc: 0.6000\n",
            "Epoch 31/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.8982\n",
            "Epoch 00031: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2409 - acc: 0.8959 - val_loss: 0.8209 - val_acc: 0.5000\n",
            "Epoch 32/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.8860\n",
            "Epoch 00032: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2526 - acc: 0.8865 - val_loss: 0.6540 - val_acc: 0.6000\n",
            "Epoch 33/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9171\n",
            "Epoch 00033: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2117 - acc: 0.9172 - val_loss: 0.6563 - val_acc: 0.5000\n",
            "Epoch 34/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9133\n",
            "Epoch 00034: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2113 - acc: 0.9135 - val_loss: 0.7475 - val_acc: 0.6500\n",
            "Epoch 35/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9178\n",
            "Epoch 00035: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2039 - acc: 0.9178 - val_loss: 0.6676 - val_acc: 0.5500\n",
            "Epoch 36/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9134\n",
            "Epoch 00036: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2088 - acc: 0.9126 - val_loss: 0.7878 - val_acc: 0.6000\n",
            "Epoch 37/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.8904\n",
            "Epoch 00037: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2424 - acc: 0.8909 - val_loss: 0.7500 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9251\n",
            "Epoch 00038: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1898 - acc: 0.9251 - val_loss: 0.7390 - val_acc: 0.5000\n",
            "Epoch 39/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9262\n",
            "Epoch 00039: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1843 - acc: 0.9263 - val_loss: 0.7884 - val_acc: 0.5500\n",
            "Epoch 40/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9265\n",
            "Epoch 00040: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1829 - acc: 0.9265 - val_loss: 0.7896 - val_acc: 0.5000\n",
            "Epoch 41/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9252\n",
            "Epoch 00041: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1868 - acc: 0.9246 - val_loss: 0.9528 - val_acc: 0.5500\n",
            "Epoch 42/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.8948\n",
            "Epoch 00042: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2299 - acc: 0.8957 - val_loss: 0.7452 - val_acc: 0.4500\n",
            "Epoch 43/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9346\n",
            "Epoch 00043: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1680 - acc: 0.9348 - val_loss: 0.7996 - val_acc: 0.5000\n",
            "Epoch 44/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9345\n",
            "Epoch 00044: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1666 - acc: 0.9346 - val_loss: 0.8439 - val_acc: 0.6000\n",
            "Epoch 45/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9373\n",
            "Epoch 00045: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1610 - acc: 0.9371 - val_loss: 0.8992 - val_acc: 0.4500\n",
            "Epoch 46/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9322\n",
            "Epoch 00046: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1676 - acc: 0.9324 - val_loss: 0.9232 - val_acc: 0.6000\n",
            "Epoch 47/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9407\n",
            "Epoch 00047: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1552 - acc: 0.9404 - val_loss: 0.8701 - val_acc: 0.4500\n",
            "Epoch 48/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.8720\n",
            "Epoch 00048: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.2906 - acc: 0.8729 - val_loss: 0.7440 - val_acc: 0.6500\n",
            "Epoch 49/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9318\n",
            "Epoch 00049: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1748 - acc: 0.9321 - val_loss: 0.8098 - val_acc: 0.5500\n",
            "Epoch 50/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9391\n",
            "Epoch 00050: val_acc did not improve from 0.75000\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 0.1614 - acc: 0.9393 - val_loss: 0.8283 - val_acc: 0.5500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e5a6c7e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMQwXHsSOAGn",
        "colab_type": "code",
        "outputId": "049ac3fd-f14d-47ff-a096-bbe515e7365e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "val_loss, val_acc = model.evaluate(x_test_augmented,y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 0s 61us/sample - loss: 0.8283 - acc: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-shhLHZPFLV",
        "colab_type": "code",
        "outputId": "79128a06-6b4d-4b6d-d9a0-3409191dd829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"loss:\",val_loss)\n",
        "predictions = model.predict(x_test_augmented)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.8282866477966309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQf8UafCPHZj",
        "colab_type": "code",
        "outputId": "dfdfda29-42ea-4289-fef2-d076f2c81fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import random\n",
        "index = random.randint(0,19)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test[index], cmap='gray')\n",
        "plt.show()\n",
        "if(np.argmax(predictions[index]) == 1):\n",
        "  print('Brain !')\n",
        "else:\n",
        "  print('Not brain !')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhcgUiV+ITPl/9bZya4Tcq2oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Not brain !\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}